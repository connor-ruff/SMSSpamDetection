{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPool1D, Embedding, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Read In Data and Format It Better\n",
    "df = pd.read_csv('spam.csv', sep=',', encoding='ISO-8859-1')\n",
    "df = df.drop(columns=[ \"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Result</th>\n",
       "      <th>Message_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  Result  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...       0   \n",
       "1   ham                      Ok lar... Joking wif u oni...       0   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...       1   \n",
       "3   ham  U dun say so early hor... U c already then say...       0   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...       0   \n",
       "\n",
       "   Message_Size  \n",
       "0           111  \n",
       "1            29  \n",
       "2           155  \n",
       "3            49  \n",
       "4            61  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # Add 2 New Columns: For binary spam/ham indicator and length of message\n",
    "df['Result']= df['v1'].map( {'spam' : int(1), 'ham' : int(0)})\n",
    "df['Message_Size'] = df['v2'].apply(len)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747 of 5572 messages are spam: 13.406317300789663%\n"
     ]
    }
   ],
   "source": [
    " # Calculate Statistics\n",
    "totalMessages = df['Result'].count()\n",
    "numSpams = df[df['Result']==1]['Result'].count()\n",
    "numValid = df[df['Result'] == 0]['Result'].count()\n",
    "# Print Distribution\n",
    "print(f'{numSpams} of {totalMessages} messages are spam: {((numSpams/totalMessages)*100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yingqiu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Result</th>\n",
       "      <th>Message_Size</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  Result  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...       0   \n",
       "1   ham                      Ok lar... Joking wif u oni...       0   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...       1   \n",
       "3   ham  U dun say so early hor... U c already then say...       0   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...       0   \n",
       "\n",
       "   Message_Size                                             Tokens  \n",
       "0           111  [Go, until, jurong, point, ,, crazy, .., Avail...  \n",
       "1            29           [Ok, lar, ..., Joking, wif, u, oni, ...]  \n",
       "2           155  [Free, entry, in, 2, a, wkly, comp, to, win, F...  \n",
       "3            49  [U, dun, say, so, early, hor, ..., U, c, alrea...  \n",
       "4            61  [Nah, I, do, n't, think, he, goes, to, usf, ,,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "# Tokenize Each Message and add the list of tokens to the DataFrame\n",
    "df['Tokens'] = df['v2'].apply(word_tokenize)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yingqiu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "special_words = ['...']\n",
    "nltk.download('stopwords')\n",
    "# Add Tokenize With Removed Stop Words\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminateStop(words):\n",
    "# Remove stopwords\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "# Remove special words\n",
    "    words = [w for w in words if not w in special_words]\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "    returnList = [word.lower() for word in words]\n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Result</th>\n",
       "      <th>Message_Size</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Filtered_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "      <td>[go, jurong, point, crazy, .., available, bugi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "      <td>[dun, say, early, hor, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "      <td>[nah, n't, think, goes, usf, lives, around, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  Result  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...       0   \n",
       "1   ham                      Ok lar... Joking wif u oni...       0   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...       1   \n",
       "3   ham  U dun say so early hor... U c already then say...       0   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...       0   \n",
       "\n",
       "   Message_Size                                             Tokens  \\\n",
       "0           111  [Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1            29           [Ok, lar, ..., Joking, wif, u, oni, ...]   \n",
       "2           155  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3            49  [U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4            61  [Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                     Filtered_Tokens  \n",
       "0  [go, jurong, point, crazy, .., available, bugi...  \n",
       "1                        [ok, lar, joking, wif, oni]  \n",
       "2  [free, entry, wkly, comp, win, fa, cup, final,...  \n",
       "3               [dun, say, early, hor, already, say]  \n",
       "4  [nah, n't, think, goes, usf, lives, around, th...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Filtered_Tokens'] = df['Tokens'].apply(eliminateStop)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call;346\n",
      "free;219\n",
      "txt;156\n",
      "ur;144\n",
      "mobile;123\n",
      "text;121\n",
      "stop;114\n",
      "claim;113\n",
      "you;107\n",
      "reply;104\n",
      "prize;92\n",
      "get;84\n",
      "to;79\n",
      "your;76\n",
      "'s;72\n",
      "new;69\n",
      "send;68\n",
      "nokia;65\n",
      "cash;62\n",
      "urgent;62\n"
     ]
    }
   ],
   "source": [
    "#find the 20 most common words used in spam SMS\n",
    "df_spam = df.loc[df['v1'] == 'spam']\n",
    "list_all_spam = df_spam['Filtered_Tokens'].tolist()\n",
    "list_all_spam = [words for sublist in list_all_spam for words in sublist]\n",
    "\n",
    "fdist = nltk.FreqDist(list_all_spam)\n",
    "for word, frequency in fdist.most_common(20):\n",
    "    print(u'{};{}'.format(word, frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s;420\n",
      "'m;387\n",
      "n't;345\n",
      "gt;318\n",
      "lt;316\n",
      "get;301\n",
      "'';264\n",
      "go;246\n",
      "ok;246\n",
      "got;242\n",
      "ur;237\n",
      "know;234\n",
      "you;233\n",
      "like;231\n",
      "call;230\n",
      "'ll;228\n",
      "good;227\n",
      "come;225\n",
      "time;195\n",
      "love;180\n"
     ]
    }
   ],
   "source": [
    "#find the 20 most common words used in ham SMS\n",
    "df_ham = df.loc[df['v1'] == 'ham']\n",
    "list_all_ham = df_ham['Filtered_Tokens'].tolist()\n",
    "list_all_ham = [words for sublist in list_all_ham for words in sublist]\n",
    "\n",
    "fdist = nltk.FreqDist(list_all_ham)\n",
    "for word, frequency in fdist.most_common(20):\n",
    "    print(u'{};{}'.format(word, frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', 'jurong', 'point', 'crazy', '..', 'available', 'bugis', 'great', 'world', 'la', 'buffet', 'cine', 'got', 'amore', 'wat'], ['ok', 'lar', 'joking', 'wif', 'oni']]\n"
     ]
    }
   ],
   "source": [
    "word_token = []\n",
    "for i in df['Filtered_Tokens']:\n",
    "    word_token.append(i)\n",
    "print(word_token[: 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=9362, size=500, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = Word2Vec(word_token, size=500, window=3, min_count=1, workers=16)\n",
    "print(word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0   12 4370  738  694    1  589 1201   69  252 1202\n",
      "  2866 1203   16 4371   76]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    14  253 1547  376 1801]]\n"
     ]
    }
   ],
   "source": [
    "token = Tokenizer(9362)\n",
    "token.fit_on_texts(df['Filtered_Tokens'])\n",
    "text = token.texts_to_sequences(df['Filtered_Tokens'])\n",
    "text = pad_sequences(text, 75)\n",
    "print(text[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df['Result'])\n",
    "y = to_categorical(y)\n",
    "y[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(text), y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "279/279 [==============================] - 16s 58ms/step - loss: 0.2088 - acc: 0.9284 - val_loss: 0.0731 - val_acc: 0.9803\n",
      "Epoch 2/3\n",
      "279/279 [==============================] - 16s 57ms/step - loss: 0.0314 - acc: 0.9908 - val_loss: 0.0872 - val_acc: 0.9794\n",
      "Epoch 3/3\n",
      "279/279 [==============================] - 15s 56ms/step - loss: 0.0150 - acc: 0.9975 - val_loss: 0.1255 - val_acc: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8f175281d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model = Sequential()\n",
    "keras_model.add(word2vec_model.wv.get_keras_embedding(True))\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Conv1D(50, 3, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(Conv1D(50, 3, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(MaxPool1D())\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Conv1D(100, 3, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(Conv1D(100, 3, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(MaxPool1D())\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Conv1D(200, 3, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(Conv1D(200, 3, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(GlobalMaxPool1D())\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Dense(200))\n",
    "keras_model.add(Activation('relu'))\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Dense(2))\n",
    "keras_model.add(Activation('softmax'))\n",
    "keras_model.compile(loss='binary_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "keras_model.fit(x_train, y_train, batch_size=16, epochs=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference: https://www.kaggle.com/jagannathrk/word2vec-cnn-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
